# -*- coding: utf-8 -*-
"""INMERSION_DATOS_AULA_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hbUKq7q9EoHaWpVWJ7N8WFUwHlmU2G2G

<a href="https://colab.research.google.com/github/ahcamachod/inmersion-en-datos/blob/aula-2/INMERSION_DATOS_AULA_2.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# Aula 1
"""

from google.colab import drive

drive.mount('/content/drive')

"""##Importando libreria Pandas"""

import pandas as pd

inmuebles = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 01 - TU PRIMER COLAB CON PYTHON Y PANDAS/Bases de datos/inmuebles_bogota.csv')
inmuebles.head()

"""## Análisis exploratorio

Cantidad de datos en la tabla
"""

inmuebles.shape

"""Valores de las columnas de la tabla"""

inmuebles.columns

"""Renombrando columnas"""

columnas = {'Baños':'Banos','Área':'Area'}
inmuebles = inmuebles.rename(columns=columnas)
inmuebles.sample(10)

"""Información del dataset"""

inmuebles.info()

"""Localizar por medio del indice"""

inmuebles.iloc[300]

inmuebles.iloc[300:305]

inmuebles['Valor'][300]

type(inmuebles['Valor'][300:305])

inmuebles.columns

"""Cálculo del promedio de area que poseen los inmuebles"""

inmuebles.Area.mean()

inmuebles.sample(100)

(inmuebles.Barrio == 'Chico Reservado')

"""Cantidad de inmuebles en el barrio indicado"""

sum((inmuebles.Barrio == 'Chico Reservado'))

""" Tipo de variable"""

inmuebles_chico = (inmuebles.Barrio == 'Chico Reservado')
type(inmuebles_chico)

chico_reservado = inmuebles[inmuebles_chico]
chico_reservado

"""Area promedio del barrio"""

chico_reservado.Area.mean()

inmuebles.Area.mean()

len(inmuebles.Barrio.value_counts())

inmuebles.Barrio.value_counts()

len(inmuebles.UPZ.value_counts())

"""Cantidad de inmuebles por barrio"""

inmuebles_barrio = inmuebles.Barrio.value_counts()
inmuebles_barrio.head(10).plot.bar()

inmuebles_barrio.head(10).plot.bar()

"""##**Desafío**


1. Promedio de área de todos los inmuebles en los barrios en el dataset. El top 10.

2. Consultar otros datos estadísticos, conteo, mediana, valores mínimo y máximo.

### Desafío 1
"""

promedio_area = inmuebles.groupby('Barrio')['Area'].median()
promedio_area.sort_values(ascending=False).head(10).plot.bar(color='green')

"""### Desafío 2"""

# Desafio 2:
inmuebles_barrio.describe()

"""#**Aula 2**"""

inmuebles.sample(5)

inmuebles.info()

type(inmuebles.Valor[0])

inmuebles.Valor[0]+inmuebles.Valor[1]+inmuebles.Valor[:5]

"""* Se utiliza ***split*** para separar $ de la cantidad
*   ***str*** se utiliza para trabajar como string (en una lista) ya que es un pandas.series

"""

inmuebles.Valor[0].split()

"""Tratamiento de valores para separar el simbolo de la moneda y el dato numerico del precio:

- Usando el parametro ***expand=True*** me devuelve un formato de DataFrame
-  Se almacena en una variable y se agregan dos columnas  nuevas al DataFrame
"""

valor = inmuebles.Valor.str.split(expand=True)
inmuebles['Moneda'] = valor[0]
inmuebles['Precio'] = valor[1]
inmuebles.sample(3)

inmuebles.info()

inmuebles['Precio'].sum()

"""Tratando los datos de la columna Precio de str a numerico


*   Elimina el separador "." utilizando .replace (regex=True se agrega por actualizacion de python)
*   Convertir str a float, utilizando **astype** en un nuevo atributo Precio Millon


"""

# Tratamiento de valor para excluir los puntos/comas
inmuebles['Precio'] = inmuebles['Precio'].str.replace('.','',regex=True)

inmuebles[['Precio','Barrio']]

inmuebles.info()

# Conversion de valores a millon
inmuebles['Precio_Millon'] = inmuebles.Precio.astype('float')/1000000
inmuebles.info()

inmuebles.describe()

"""Eliminar posiciones decimales"""

pd.set_option('display.precision',2) # Asigna una precision de 2 decimales
pd.set_option('display.float_format', lambda x: '%.2f' % x)
inmuebles.describe()

inmuebles.loc[inmuebles.Habitaciones == 110] # Localiza los inmuebles con la cantidad de habitaciones indicada: 110

inmuebles.loc[inmuebles.Area == 2] # Localiza los inmuebles con el area indicada: 1

inmuebles['Precio_Millon'].plot.hist(bins=10)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6)) # Fijacion del tamaño del grafico
grafica = sns.histplot(data=inmuebles, x='Precio_Millon', kde=True, hue='Tipo')
grafica.set_title('Distribución de Valores de los inmuebles en Bogotá')
plt.xlim((50,1000))
plt.savefig('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 02 - TRATAMIENTO DE DATOS Y PRIMEROS GRÁFICOS/Gráficos/valor_inmuebles.png',format='png')
plt.show()

"""## **Desafíos**

1. Estudiar mejor el histograma de valores, seleccionar 3 tipos de inmuebles (Refinar el gráfico: Títulos, aumentar el tamaño de labels, colores, conclusión de la información)

2. Precio del m2 por barrio y hacer el gráfico más adecuado para esta nueva variable.

### Desafío 1
"""

inmuebles_desafio = inmuebles[inmuebles.Tipo.isin(['Lote', 'Bodega', 'Local'])]
inmuebles_desafio.head()

plt.figure(figsize=(10,6))
grafica_desafio = sns.histplot(data=inmuebles_desafio, x='Precio_Millon', kde=True, hue='Tipo', element="step", multiple="stack", palette = "rocket")

grafica_desafio.set_title('Distribucion de los Valores de los Inmuebles en Bogotá')
plt.xlim((50,6000))
plt.xlabel('Precio en Millones de Pesos Colombianos')
plt.ylabel('Cantidad de Inmuebles')

plt.show()

"""### Desafio 2"""

inmuebles['Precio_m2'] = inmuebles['Precio_Millon'] / inmuebles['Area']
inmuebles.head()

precio_m2_inmuebles=inmuebles[['Barrio','Precio_m2']].groupby(['Barrio']).mean().sort_values(by=['Precio_m2'], ascending=False).head(10)

precio_m2_inmuebles.plot(kind='bar', color = "darkseagreen")

plt.xlabel('Barrio')
plt.ylabel('Precio m2 promedio')
plt.title('10 Barrios de mayor precio por metro cuadrado')
plt.show()

"""#**Aula 3**"""

inmuebles['Valor_m2_Millon'] = inmuebles['Precio_Millon']/inmuebles['Area']
inmuebles.head(3)

inmuebles.groupby('Barrio').mean()

datos_barrio = inmuebles.groupby('Barrio').sum()
datos_barrio

datos_barrio['Valor_m2_Barrio'] = datos_barrio['Precio_Millon']/datos_barrio['Area']
datos_barrio

m2_barrio = dict(datos_barrio['Valor_m2_Barrio'])

inmuebles['Valor_m2_Barrio'] = inmuebles['Barrio']
inmuebles['Valor_m2_Barrio'] = inmuebles['Valor_m2_Barrio'].map(m2_barrio)
inmuebles.head(5)

top_barrios = inmuebles['Barrio'].value_counts()[:10].index

datos_barrio.reset_index(inplace=True)
datos_barrio

datos_barrio.query('Barrio in @top_barrios')

plt.figure(figsize=(10,8))
ax = sns.barplot(x="Barrio", y="Valor_m2_Barrio", data = datos_barrio.query('Barrio in @top_barrios'))
ax.tick_params(axis='x', rotation=45)

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Valor_m2_Millon", data = inmuebles.query('Barrio in @top_barrios'))
ax.tick_params(axis='x', rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Valor_m2_Millon", data = inmuebles.query('Barrio in @top_barrios & Valor_m2_Millon < 15'))
ax.tick_params(axis='x', rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Area", data = inmuebles.query('Barrio in @top_barrios & Area < 500'))
ax.tick_params(axis='x', rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Precio_Millon", data = inmuebles.query('Barrio in @top_barrios & Precio_Millon < 2000'))
ax.tick_params(axis='x', rotation=45)
plt.show()

"""Vamos a traer datos estadísticos de la ciudad de Bogotá, directamente del DANE y vamos a ver como estos datos nos ayudarían en inclusión de nuevas variables para el cálculo del precio de los inmuebles en la ciudad de Bogotá.

Encuesta Multiproposito de Bogotá para obtener información socio-económica y de entorno urbano de los habitantes de Bogotá para la formulación, seguimiento y evaluación de las políticas distritales.


https://microdatos.dane.gov.co/index.php/catalog/743
"""

datos_raw = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Identificación (Capítulo A).csv', sep = ';',encoding='latin-1')
datos_raw.head()

datos_raw.shape

datos_raw = datos_raw.loc[datos_raw.MPIO == 11001]
datos_raw.shape

"""Añadiendo bases de datos"""

datos_b = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Datos de la vivenda y su entorno (Capítulo B).csv',sep=';',encoding='latin-1')
datos_c = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Condiciones habitacionales del hogar (Capítulo C).csv',sep=';',encoding='latin-1')
datos_e = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Composición del hogar y demografía (Capítulo E).csv',sep=';',encoding='latin-1')
datos_h = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Educación (Capitulo H).csv',sep=';',encoding='latin-1')
datos_l = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Percepción sobre las condiciones de vida y el desempeño institucional (Capítulo L).csv',sep=';',encoding='latin-1')
datos_k = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 03 - PROFUNDIZANDO EL ANÁLISIS EXPLORATORIO/Cuaderno/Base de datos/Fuerza de trabajo (Capítulo K).csv',sep=';',encoding='latin-1')

datos_dane = pd.merge(datos_raw,datos_b,on='DIRECTORIO', how='left')
datos_dane.shape

datos_dane = pd.merge(datos_dane,datos_c,on='DIRECTORIO', how='left')
datos_dane.shape

datos_dane = pd.merge(datos_dane,datos_e,on='DIRECTORIO', how='left')

datos_dane.shape

datos_dane.info()

"""**Desafío**

1. Dar un vistazo a la base de datos del DANE, entender estas variables conceptualmente para entender mejor el contexto de esta base.
2.  Organizar tu notebook para que tu proyecto quede mejor presentado.

#**Aula 4**
"""

datos_dane = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 04 - CRUZANDO BASES Y MACHINE LEARNING/Cuaderno/Bases de datos/datos_dane.csv')
datos_dane.head()

datos_dane.shape

datos_dane.info()

"""##Renombrando nuevos campos"""

dic_dane = {
       'NVCBP4':'CONJUNTO_CERRADO',
       'NVCBP14A':'FABRICAS_CERCA', 'NVCBP14D':'TERMINALES_BUS', 'NVCBP14E':'BARES_DISCO',
       'NVCBP14G':'OSCURO_PELIGROSO', 'NVCBP15A':'RUIDO', 'NVCBP15C':'INSEGURIDAD',
       'NVCBP15F':'BASURA_INADECUADA', 'NVCBP15G':'INVASION','NVCBP16A3':'MOV_ADULTOS_MAYORES',
       'NVCBP16A4':'MOV_NINOS_BEBES',
       'NPCKP17':'OCUPACION','NPCKP18':'CONTRATO','NPCKP23':'SALARIO_MES',
       'NPCKP44A':'DONDE_TRABAJA', 'NPCKPN62A':'DECLARACION_RENTA',
       'NPCKPN62B':'VALOR_DECLARACION', 'NPCKP64A':'PERDIDA_TRABAJO_C19',
       'NPCKP64E':'PERDIDA_INGRESOS_C19',
       'NHCCP3':'TIENE_ESCRITURA', 'NHCCP6':'ANO_COMPRA', 'NHCCP7':'VALOR_COMPRA', 'NHCCP8_1':'HIPOTECA_CRED_BANCO',
       'NHCCP8_2':'OTRO_CRED_BANCO', 'NHCCP8_3':'CRED_FNA', 'NHCCP8_6':'PRESTAMOS_AMIGOS',
       'NHCCP8_7':'CESANTIAS', 'NHCCP8_8':'AHORROS', 'NHCCP8_9':'SUBSIDIOS',
       'NHCCP9':'CUANTO_PAGARIA_MENSUAL', 'NHCCP11':'PLANES_ADQUIRIR_VIVIENDA',
       'NHCCP11A':'MOTIVO_COMPRA', 'NHCCP12':'RAZON_NO_ADQ_VIV', 'NHCCP41':'TIENE_CARRO','NHCCP41A':'CUANTOS_CARROS',
       'NHCCP47A':'TIENE_PERROS', 'NHCCP47B':'TIENE_GATOS', 'NHCLP2A':'VICTIMA_ATRACO', 'NHCLP2B':'VICTIMA_HOMICIDIO',
       'NHCLP2C':'VICTIMA_PERSECUSION',
       'NHCLP2E':'VICTIMA_ACOSO', 'NHCLP4':'COMO_VIVE_ECON', 'NHCLP5':'COMO_NIVEL_VIDA',
       'NHCLP8AB':'REACCION_OPORTUNA_POLICIA', 'NHCLP8AE':'COMO_TRANSPORTE_URBANO', 'NHCLP10':'SON_INGRESOS_SUFICIENTES',
       'NHCLP11':'SE_CONSIDERA_POBRE', 'NHCLP29_1A':'MED_C19_TRABAJO',
       'NHCLP29_1C':'MED_C19_CAMBIO_VIVIENDA', 'NHCLP29_1E':'MED_C19_ENDEUDAMIENTO',
       'NHCLP29_1F':'MED_C19_VENTA_BIENES','NPCHP4':'NIVEL_EDUCATIVO'
       }

datos_dane = datos_dane.rename(columns=dic_dane)
datos_dane.columns

datos_dane.info()

datos_dane.groupby('NOMBRE_ESTRATO')[['CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].mean().head()

"""##Adaptación de los datos"""

datos = datos_dane[['NOMBRE_ESTRATO','CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].replace(2,0)
datos

datos.loc[datos.NOMBRE_ESTRATO == '20 de Julio']

datos_tratados = datos.groupby('NOMBRE_ESTRATO')[['CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].mean()
datos_tratados

"""##Efectuando los merge"""

pd.merge(inmuebles,datos_tratados, left_on='UPZ', right_on='NOMBRE_ESTRATO', how='left')

datos_ml = pd.merge(inmuebles,datos_tratados, left_on='UPZ', right_on='NOMBRE_ESTRATO', how='left')
datos_ml.info()

"""##Agregando códigos de UPZ(Unidades de Planeamiento Zonal)"""

upz = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alura Latam/Seminarios/Inmersion de datos_ con Python/CLASE 04 - CRUZANDO BASES Y MACHINE LEARNING/Cuaderno/Bases de datos/cod_upz.csv')
datos_ml = pd.merge(datos_ml,upz,left_on='UPZ',right_on='NOMBRE_ESTRATO', how='inner')
datos_ml.head()

datos_ml.shape

datos_ml.info()

"""##Revisión de la distribución de los datos"""

plt.figure(figsize=(10,8))
sns.boxplot(data=datos_ml, y = 'Precio_Millon')
plt.show()

datos_ml.query('Precio_Millon > 5000 | Precio_Millon < 60')

datos_ml = datos_ml.query('Precio_Millon < 1200 & Precio_Millon > 60')
datos_ml

plt.figure(figsize=(10,8))
sns.boxplot(data=datos_ml, y = 'Precio_Millon')
plt.show()

datos_ml['SALARIO_ANUAL_MI'] = datos_ml['SALARIO_MES']*12/1000000
datos_ml['SALARIO_ANUAL_MI']

plt.figure(figsize=(10,8))
sns.scatterplot(data=datos_ml, x='SALARIO_ANUAL_MI',y ='Valor_m2_Millon')
plt.ylim((0,15))
plt.show()

"""##Correlacion de los campos"""

datos_ml.corr()

plt.figure(figsize=(18, 8))
#https://www.tylervigen.com/spurious-correlations
#mascara = np.triu(np.ones_like(datos_ml.corr(), dtype=bool)) mask=mascara,
heatmap = sns.heatmap(datos_ml.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Correlación de las variables', fontdict={'fontsize':18}, pad=16);

"""##Entrenamiento de modelo de Machine Learning"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = datos_ml[['COD_UPZ_GRUPO']]
y = datos_ml['Precio_Millon']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=99)

X_train

X_test

y_train

"""Instanciando regresion lineal"""

modelo = LinearRegression()

modelo.fit(X_train,y_train)

y_predict_test = modelo.predict(X_test)

from sklearn.metrics import mean_absolute_error, r2_score

baseline_mae = mean_absolute_error(y_test, y_predict_test)
baseline_r2 = r2_score(y_test, y_predict_test)
print(baseline_mae,baseline_r2)

from sklearn.metrics import mean_absolute_error, r2_score

baseline_mae = mean_absolute_error(y_test, y_predict_test)
baseline_r2 = r2_score(y_test, y_predict_test)
print(baseline_mae,baseline_r2)

"""##Revisión con aumento en la cantidad de campos"""

X = datos_ml[['COD_UPZ_GRUPO','Habitaciones','Banos','CONJUNTO_CERRADO','SALARIO_ANUAL_MI','TIENE_ESCRITURA']]

y = datos_ml["Precio_Millon"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 99)
modelo_1 = LinearRegression()
modelo_1.fit(X_train, y_train)
y_predict_test = modelo_1.predict(X_test)
y_predict_train = modelo_1.predict(X_train)
mae_test = mean_absolute_error(y_test, y_predict_test)
r2_test = r2_score(y_test, y_predict_test)
mae_train = mean_absolute_error(y_train, y_predict_train)
r2_train = r2_score(y_train, y_predict_train)
print(mae_test,r2_test)
print(mae_train,r2_train)

X = datos_ml[['COD_UPZ_GRUPO','Habitaciones','Banos','CONJUNTO_CERRADO','SALARIO_ANUAL_MI','TIENE_ESCRITURA']]

y = datos_ml["Precio_Millon"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 99)
modelo_1 = LinearRegression()
modelo_1.fit(X_train, y_train)
y_predict_test = modelo_1.predict(X_test)
y_predict_train = modelo_1.predict(X_train)
mae_test = mean_absolute_error(y_test, y_predict_test)
r2_test = r2_score(y_test, y_predict_test)
mae_train = mean_absolute_error(y_train, y_predict_train)
r2_train = r2_score(y_train, y_predict_train)
print(mae_test,r2_test)
print(mae_train,r2_train)

# COD_UPZ: 816
# Habitaciones: 3
# Baños: 2
# Conjunto Cerrado: 1
# Salario Anual en Millones: 50
# Tiene escritura: 1
modelo_1.predict([[816,3,2,1,50,1]])

# El resultados es el valor del inmueble

